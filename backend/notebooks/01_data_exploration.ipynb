{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QuickBooks Commerce - Sales Forecasting Data Exploration\n",
        "\n",
        "This notebook explores the synthetic sales data used for training the ensemble model (XGBoost + Holt-Winters).\n",
        "\n",
        "**Model**: Ensemble v2.0.0 — XGBoost (60%) + Holt-Winters (40%)  \n",
        "**Features**: 17 engineered features  \n",
        "**Holdout R²**: 0.82"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "\n",
        "We use synthetic data with category-specific baselines and realistic seasonality.\n",
        "The same data generation approach is used in `scripts/train_model.py`.\n",
        "\n",
        "In production, you would load from:\n",
        "- QuickBooks Commerce API (real merchant sales)\n",
        "- FRED API (economic indicators)\n",
        "- Yahoo Finance (market trends)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic sales data (matches data_service.py approach)\n",
        "np.random.seed(42)  # Reproducible\n",
        "\n",
        "def generate_sales_data(days=366):\n",
        "    \"\"\"Generate realistic synthetic sales data with category-specific baselines\"\"\"\n",
        "    categories = [\n",
        "        'Electronics', 'Clothing', 'Home & Garden',\n",
        "        'Sports & Outdoors', 'Books & Media', 'Food & Beverages',\n",
        "        'Health & Beauty', 'Toys & Games'\n",
        "    ]\n",
        "    \n",
        "    # Category-specific base sales (matches trained model)\n",
        "    category_base = {\n",
        "        'Electronics': 1800,\n",
        "        'Clothing': 1200,\n",
        "        'Home & Garden': 900,\n",
        "        'Sports & Outdoors': 1000,\n",
        "        'Books & Media': 600,\n",
        "        'Food & Beverages': 1500,\n",
        "        'Health & Beauty': 800,\n",
        "        'Toys & Games': 700,\n",
        "    }\n",
        "    \n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=days)\n",
        "    \n",
        "    data = []\n",
        "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "    \n",
        "    for date in date_range:\n",
        "        for category in categories:\n",
        "            base_sales = category_base.get(category, 1000) + np.random.uniform(-200, 200)\n",
        "            \n",
        "            # Monthly seasonality\n",
        "            month_factor = 1.0 + 0.15 * np.sin(2 * np.pi * date.month / 12)\n",
        "            \n",
        "            # Weekend boost\n",
        "            weekend_boost = 1.15 if date.weekday() >= 5 else 1.0\n",
        "            \n",
        "            # Random noise\n",
        "            noise = np.random.normal(0, base_sales * 0.08)\n",
        "            \n",
        "            sales = max(0, base_sales * month_factor * weekend_boost + noise)\n",
        "            \n",
        "            data.append({\n",
        "                'date': date,\n",
        "                'category': category,\n",
        "                'sales_units': int(sales),\n",
        "                'revenue': round(sales * np.random.uniform(30, 80), 2)\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df = generate_sales_data()\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Categories: {df['category'].nunique()}\")\n",
        "print(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"\\nDataset Info:\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "print(f\"Categories: {df['category'].nunique()}\")\n",
        "print(f\"Total records: {len(df)}\")\n",
        "\n",
        "print(\"\\nSales Statistics by Category:\")\n",
        "df.groupby('category').agg({\n",
        "    'sales_units': ['mean', 'std', 'min', 'max'],\n",
        "    'revenue': 'sum'\n",
        "}).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sales trend over time\n",
        "plt.figure(figsize=(14, 6))\n",
        "for category in df['category'].unique():\n",
        "    cat_data = df[df['category'] == category].groupby('date')['sales_units'].sum()\n",
        "    plt.plot(cat_data.index, cat_data.values, label=category, alpha=0.7)\n",
        "\n",
        "plt.title('Sales Trend by Category Over Time', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sales Units')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Category performance comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Total sales by category\n",
        "category_sales = df.groupby('category')['sales_units'].sum().sort_values(ascending=True)\n",
        "category_sales.plot(kind='barh', ax=axes[0], color='steelblue')\n",
        "axes[0].set_title('Total Sales by Category', fontweight='bold')\n",
        "axes[0].set_xlabel('Sales Units')\n",
        "\n",
        "# Revenue by category\n",
        "category_revenue = df.groupby('category')['revenue'].sum().sort_values(ascending=True)\n",
        "category_revenue.plot(kind='barh', ax=axes[1], color='coral')\n",
        "axes[1].set_title('Total Revenue by Category', fontweight='bold')\n",
        "axes[1].set_xlabel('Revenue ($)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasonality analysis\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day_of_week'] = df['date'].dt.dayofweek\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Monthly pattern\n",
        "monthly_sales = df.groupby('month')['sales_units'].mean()\n",
        "axes[0].bar(monthly_sales.index, monthly_sales.values, color='teal')\n",
        "axes[0].set_title('Average Daily Sales by Month', fontweight='bold')\n",
        "axes[0].set_xlabel('Month')\n",
        "axes[0].set_ylabel('Average Sales Units')\n",
        "axes[0].set_xticks(range(1, 13))\n",
        "\n",
        "# Weekly pattern\n",
        "weekly_sales = df.groupby('day_of_week')['sales_units'].mean()\n",
        "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[1].bar(range(7), weekly_sales.values, color='purple')\n",
        "axes[1].set_title('Average Sales by Day of Week', fontweight='bold')\n",
        "axes[1].set_xlabel('Day of Week')\n",
        "axes[1].set_ylabel('Average Sales Units')\n",
        "axes[1].set_xticks(range(7))\n",
        "axes[1].set_xticklabels(days)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"Create time-series features\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Time features\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['quarter'] = df['date'].dt.quarter\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day'] = df['date'].dt.day\n",
        "    df['day_of_week'] = df['date'].dt.dayofweek\n",
        "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # Lag features\n",
        "    for lag in [7, 14, 30]:\n",
        "        df[f'sales_lag_{lag}'] = df.groupby('category')['sales_units'].shift(lag)\n",
        "    \n",
        "    # Rolling features\n",
        "    for window in [7, 30]:\n",
        "        df[f'sales_rolling_mean_{window}'] = df.groupby('category')['sales_units'].transform(\n",
        "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
        "        )\n",
        "        df[f'sales_rolling_std_{window}'] = df.groupby('category')['sales_units'].transform(\n",
        "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
        "        )\n",
        "    \n",
        "    return df\n",
        "\n",
        "df_features = create_features(df)\n",
        "print(\"\\nFeatures created:\")\n",
        "print(df_features.columns.tolist())\n",
        "df_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save for model training\n",
        "import os\n",
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "\n",
        "df_features.to_csv('../data/processed/sales_features.csv', index=False)\n",
        "print(\"Data saved to: ../data/processed/sales_features.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Insights\n",
        "\n",
        "1. **Category-Specific Baselines**: Electronics (~1800) is highest, Books & Media (~600) is lowest\n",
        "2. **Weekend Effect**: ~15% sales boost on weekends\n",
        "3. **Monthly Seasonality**: Cyclical pattern driven by sin(month/12)\n",
        "4. **Noise**: ~8% standard deviation gives realistic variation\n",
        "\n",
        "## Trained Model (v2.0.0)\n",
        "\n",
        "The ensemble model uses these patterns:\n",
        "- **XGBoost** (60% weight): 17 features including lag, rolling stats, time features\n",
        "- **Holt-Winters** (40% weight): Per-category weekly seasonality (period=7)\n",
        "- **Holdout R²**: 0.82 on last 30 days\n",
        "\n",
        "To train the model:\n",
        "```bash\n",
        "cd backend\n",
        "python -m scripts.train_model\n",
        "```\n",
        "\n",
        "Next steps for improvement:\n",
        "- Integrate real sales data (QuickBooks API)\n",
        "- Add external indicators (FRED API for GDP, inflation)\n",
        "- Cross-validation for hyperparameter tuning\n",
        "- Feature selection to reduce overfitting gap"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
